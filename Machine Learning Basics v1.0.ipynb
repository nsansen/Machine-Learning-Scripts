{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6.196000e+03</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.931407</td>\n",
       "      <td>1.068828e+06</td>\n",
       "      <td>9.751097</td>\n",
       "      <td>3101.947708</td>\n",
       "      <td>2.902034</td>\n",
       "      <td>1.576340</td>\n",
       "      <td>1.573596</td>\n",
       "      <td>471.006940</td>\n",
       "      <td>141.568645</td>\n",
       "      <td>1964.081988</td>\n",
       "      <td>-37.807904</td>\n",
       "      <td>144.990201</td>\n",
       "      <td>7435.489509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.971079</td>\n",
       "      <td>6.751564e+05</td>\n",
       "      <td>5.612065</td>\n",
       "      <td>86.421604</td>\n",
       "      <td>0.970055</td>\n",
       "      <td>0.711362</td>\n",
       "      <td>0.929947</td>\n",
       "      <td>897.449881</td>\n",
       "      <td>90.834824</td>\n",
       "      <td>38.105673</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>0.099165</td>\n",
       "      <td>4337.698917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.310000e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>-38.164920</td>\n",
       "      <td>144.542370</td>\n",
       "      <td>389.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.200000e+05</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>3044.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>-37.855438</td>\n",
       "      <td>144.926198</td>\n",
       "      <td>4383.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.800000e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3081.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>-37.802250</td>\n",
       "      <td>144.995800</td>\n",
       "      <td>6567.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.325000e+06</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>3147.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>-37.758200</td>\n",
       "      <td>145.052700</td>\n",
       "      <td>10175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000e+06</td>\n",
       "      <td>47.400000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>37000.000000</td>\n",
       "      <td>3112.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>-37.457090</td>\n",
       "      <td>145.526350</td>\n",
       "      <td>21650.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rooms         Price     Distance     Postcode     Bedroom2  \\\n",
       "count  6196.000000  6.196000e+03  6196.000000  6196.000000  6196.000000   \n",
       "mean      2.931407  1.068828e+06     9.751097  3101.947708     2.902034   \n",
       "std       0.971079  6.751564e+05     5.612065    86.421604     0.970055   \n",
       "min       1.000000  1.310000e+05     0.000000  3000.000000     0.000000   \n",
       "25%       2.000000  6.200000e+05     5.900000  3044.000000     2.000000   \n",
       "50%       3.000000  8.800000e+05     9.000000  3081.000000     3.000000   \n",
       "75%       4.000000  1.325000e+06    12.400000  3147.000000     3.000000   \n",
       "max       8.000000  9.000000e+06    47.400000  3977.000000     9.000000   \n",
       "\n",
       "          Bathroom          Car      Landsize  BuildingArea    YearBuilt  \\\n",
       "count  6196.000000  6196.000000   6196.000000   6196.000000  6196.000000   \n",
       "mean      1.576340     1.573596    471.006940    141.568645  1964.081988   \n",
       "std       0.711362     0.929947    897.449881     90.834824    38.105673   \n",
       "min       1.000000     0.000000      0.000000      0.000000  1196.000000   \n",
       "25%       1.000000     1.000000    152.000000     91.000000  1940.000000   \n",
       "50%       1.000000     1.000000    373.000000    124.000000  1970.000000   \n",
       "75%       2.000000     2.000000    628.000000    170.000000  2000.000000   \n",
       "max       8.000000    10.000000  37000.000000   3112.000000  2018.000000   \n",
       "\n",
       "         Lattitude   Longtitude  Propertycount  \n",
       "count  6196.000000  6196.000000    6196.000000  \n",
       "mean    -37.807904   144.990201    7435.489509  \n",
       "std       0.075850     0.099165    4337.698917  \n",
       "min     -38.164920   144.542370     389.000000  \n",
       "25%     -37.855438   144.926198    4383.750000  \n",
       "50%     -37.802250   144.995800    6567.000000  \n",
       "75%     -37.758200   145.052700   10175.000000  \n",
       "max     -37.457090   145.526350   21650.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Packages\n",
    "import pandas as pd\n",
    "# Set file path\n",
    "melbourne_file_path = \"/Users/nikschet/Documents/Jupyter Notebooks/melb_data.csv\"\n",
    "# read the data and store data in DataFrame titled melbourne_data\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# dropna drops missing values (think of na as \"not available\")\n",
    "melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# print a summary of the data in Melbourne data\n",
    "melbourne_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select certain column (Price) of melbourne_data\n",
    "y = melbourne_data.Price\n",
    "# Show first entries\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing Certain features of melbourne_data \n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "# Show first entries\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with missing values\n",
    "data_without_missing_values = melbourne_data.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error (also called MAE).\n",
    "# error=actualâˆ’predicted\n",
    "#With the MAE metric, we take the absolute value of each error. This converts each error to a positive number. We then take the average of those absolute errors. This is our measure of model quality. In plain English, it can be said as\n",
    "\n",
    "#On average, our predictions are off by about X.\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In many cases, you'll have both a training dataset and a test dataset. \n",
    "# You will want to drop the same columns in both DataFrames. In that case, you would write\n",
    "#  if your test data has missing values in places where your training data did not, this will result in an error.\n",
    "\n",
    "So, it's somewhat usually not the best solution. However, it can be useful when most values in a column are missing.\n",
    "cols_with_missing = [col for col in original_data.columns \n",
    "                                 if original_data[col].isnull().any()]\n",
    "redued_original_data = original_data.drop(cols_with_missing, axis=1)\n",
    "reduced_test_data = test_data.drop(cols_with_missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputation fills in the missing value with some number. \n",
    "#The imputed value won't be exactly right in most cases, but it usually gives more accurate models than dropping the column entirely.\n",
    "from sklearn.impute import SimpleImputer\n",
    "my_imputer = SimpleImputer()\n",
    "data_with_imputed_values = my_imputer.fit_transform(original_data)\n",
    "#The default behavior fills in the mean value for imputation. \n",
    "#Statisticians have researched more complex strategies, but those complex strategies typically give no benefit once you plug the results into sophisticated machine learning models.\n",
    "#One (of many) nice things about Imputation is that it can be included in a scikit-learn Pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputation #1 is the standard approach, and it usually works well. \n",
    "#However, imputed values may by systematically above or below their actual values \n",
    "#(which weren't collected in the dataset). Or rows with missing values may be unique in some other way. \n",
    "#In that case, your model would make better predictions by considering which values were originally missing. \n",
    "\n",
    "# Set file path\n",
    "melbourne_file_path = \"/Users/nikschet/Documents/Jupyter Notebooks/melb_data.csv\"\n",
    "# read the data and store data in DataFrame titled melbourne_data\n",
    "orignal_data = pd.read_csv(melbourne_file_path) \n",
    "# print a summary of the data in Melbourne data\n",
    "\n",
    "# make copy to avoid changing original data (when Imputing)\n",
    "new_data = original_data.copy()\n",
    "\n",
    "# make new columns indicating what will be imputed\n",
    "cols_with_missing = (col for col in new_data.columns \n",
    "                                 if new_data[col].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    new_data[col + '_was_missing'] = new_data[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "new_data = pd.DataFrame(my_imputer.fit_transform(new_data))\n",
    "new_data.columns = original_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation as directly above example #2\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = data.SalePrice\n",
    "X = data.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\n",
    "train_X, test_X, train_y, test_y = train_test_split(X.as_matrix(), y.as_matrix(), test_size=0.25)\n",
    "\n",
    "my_imputer = Imputer()\n",
    "train_X = my_imputer.fit_transform(train_X)\n",
    "test_X = my_imputer.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression tree and mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for the following 5 houses:\n",
      "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
      "1      2       1.0     156.0   -37.8079    144.9934\n",
      "2      3       2.0     134.0   -37.8093    144.9944\n",
      "4      4       1.0     120.0   -37.8072    144.9941\n",
      "6      3       2.0     245.0   -37.8024    144.9993\n",
      "7      2       1.0     256.0   -37.8060    144.9954\n",
      "The predictions are\n",
      "[1035000. 1465000. 1600000. 1876000. 1636000.]\n",
      "Mean Absolute Error is\n",
      "1115.7467183128902\n"
     ]
    }
   ],
   "source": [
    "#Import Packages\n",
    "import pandas as pd\n",
    "# Set file path\n",
    "melbourne_file_path = \"/Users/nikschet/Documents/Jupyter Notebooks/melb_data.csv\"\n",
    "# read the data and store data in DataFrame titled melbourne_data\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# dropna drops missing values (think of na as \"not available\")\n",
    "melbourne_data = melbourne_data.dropna(axis=0)\n",
    "\n",
    "\n",
    "# Decision Tree Regressor model\n",
    "# scikit-learn library to create your model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Select certain column (Price) of melbourne_data\n",
    "y = melbourne_data.Price\n",
    "\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "# Fit model\n",
    "melbourne_model.fit(X, y)\n",
    "print(\"Making predictions for the following 5 houses:\")\n",
    "print(X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melbourne_model.predict(X.head()))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "print(\"Mean Absolute Error is\")\n",
    "print(mean_absolute_error(y, predicted_home_prices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score_dataset FUNCTION to calculate MAE on split training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    train_size=0.7, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "\n",
    "def score_dataset(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same us above but splitting Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for the following 5 houses:\n",
      "       Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
      "4850       2       1.0      96.0  -37.85010   144.99530\n",
      "2307       2       1.0       0.0  -37.89020   144.99070\n",
      "10090      2       1.0     136.0  -37.85542   144.99571\n",
      "3645       3       2.0     205.0  -37.79930   145.02670\n",
      "4930       2       1.0     400.0  -37.73520   144.98520\n",
      "The predictions are\n",
      "[ 900000.  696750. 1120000. 1447500.  630000.]\n",
      "Mean Absolute Error is\n",
      "273269.8620615451\n"
     ]
    }
   ],
   "source": [
    "#Import Packages\n",
    "import pandas as pd\n",
    "# Set file path\n",
    "melbourne_file_path = \"/Users/nikschet/Documents/Jupyter Notebooks/melb_data.csv\"\n",
    "# read the data and store data in DataFrame titled melbourne_data\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# dropna drops missing values (think of na as \"not available\")\n",
    "melbourne_data = melbourne_data.dropna(axis=1)\n",
    "\n",
    "# Select certain column (Price) of melbourne_data\n",
    "y = melbourne_data.Price\n",
    "\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "\n",
    "\n",
    "# Decision Tree Regressor model\n",
    "# scikit-learn library to create your model\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "# Define model\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "# Fit model\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "print(\"Making predictions for the following 5 houses:\")\n",
    "print(val_X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melbourne_model.predict(val_X.head()))\n",
    "# get predicted prices on validation data\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "print(\"Mean Absolute Error is\")\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same us above , splitting Samples , Loop through number of MAX LEAF NODE to minimize Mean Absolute Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  385696\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  279794\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  261769\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  272464\n"
     ]
    }
   ],
   "source": [
    "# Compare Results from Regression Tree with defernet MAX LEAF NODES\n",
    "# The max_leaf_nodes argument provides a very sensible way to control overfitting vs underfitting. \n",
    "# The more leaves we allow the model to make, the more we move from the underfitting area to the overfitting area.\n",
    "#Import Packages\n",
    "import pandas as pd\n",
    "# Set file path\n",
    "melbourne_file_path = \"/Users/nikschet/Documents/Jupyter Notebooks/melb_data.csv\"\n",
    "# read the data and store data in DataFrame titled melbourne_data\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# dropna drops missing values (think of na as \"not available\")\n",
    "melbourne_data = melbourne_data.dropna(axis=1)\n",
    "\n",
    "# Select certain column (Price) of melbourne_data\n",
    "y = melbourne_data.Price\n",
    "\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "\n",
    "\n",
    "# Decision Tree Regressor model\n",
    "# scikit-learn library to create your model\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)\n",
    "\n",
    "for max_leaf_nodes in [5, 50, 500, 5000,]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same us above , splitting Samples , Loop through number of MAX LEAF NODE to minimize Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for the following 5 houses:\n",
      "       Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
      "4850       2       1.0      96.0  -37.85010   144.99530\n",
      "2307       2       1.0       0.0  -37.89020   144.99070\n",
      "10090      2       1.0     136.0  -37.85542   144.99571\n",
      "3645       3       2.0     205.0  -37.79930   145.02670\n",
      "4930       2       1.0     400.0  -37.73520   144.98520\n",
      "The predictions are\n",
      "[ 900000.  550000. 1120000. 1447500.  630000.]\n",
      "Mean Absolute Error is\n",
      "276467.81342801807\n",
      "best_tree_size\n",
      "500\n",
      " Tree size : MAE \n",
      "\n",
      "{5: 385696.54278937966, 25: 307919.7001056724, 50: 279794.61143891385, 100: 269191.989429751, 250: 269945.1501662939, 500: 261769.60955432768}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melbourne_file_path = \"/Users/nikschet/Documents/Jupyter Notebooks/melb_data.csv\"\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "melbourne_data = melbourne_data.dropna(axis=1)\n",
    "\n",
    "# Select certain column (Price) of melbourne_data\n",
    "y = melbourne_data.Price\n",
    "\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)\n",
    "\n",
    "\n",
    "# Write loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "scores = {leaf_size: get_mae(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in max_leaf_nodes}\n",
    "# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n",
    "best_tree_size = min(scores, key=scores.get)\n",
    "\n",
    "# Fit the model with best_tree_size. Fill in argument to make optimal size\n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)\n",
    "\n",
    "# fit the final model\n",
    "final_model.fit(X, y)\n",
    "\n",
    "\n",
    "print(\"Making predictions for the following 5 houses:\")\n",
    "print(val_X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melbourne_model.predict(val_X.head()))\n",
    "# get predicted prices on validation data\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "print(\"Mean Absolute Error is\")\n",
    "print(mean_absolute_error(val_y, val_predictions))\n",
    "print(\"best_tree_size\")\n",
    "print(best_tree_size)\n",
    "print(\" Tree size : MAE \\n\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FORESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198797.7404992468\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melbourne_file_path = \"/Users/nikschet/Documents/Jupyter Notebooks/melb_data.csv\"\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "melbourne_data = melbourne_data.dropna(axis=1)\n",
    "\n",
    "# Select certain column (Price) of melbourne_data\n",
    "y = melbourne_data.Price\n",
    "\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Ensemble model: XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 246458.3189386966\n"
     ]
    }
   ],
   "source": [
    "# XGBoost is an implementation of the Gradient Boosted Decision Trees algorithm. \n",
    "# Takes many weak learns and builds a strong learner. \n",
    "# https://www.youtube.com/watch?v=ufHo8vbk6g4\n",
    "\n",
    "# We go through cycles that repeatedly builds new models and combines them into an ensemble model. \n",
    "# We start the cycle by calculating the errors for each observation in the dataset. \n",
    "# We then build a new model to predict those. We add predictions from this error-predicting model to the \n",
    "# \"ensemble of models.\" To make a prediction, we add the predictions from all previous models. \n",
    "# We can use these predictions to calculate new errors, build the next model, and add it to the ensemble.\n",
    "# Naive model -> Calculate errors -> Build model predicting -> Add last model to Ensemble -> Calculate errors -> ...\n",
    "\n",
    "# n_estimators: specifies how many times to go through the modeling cycle described above.\n",
    "\n",
    "# The argument early_stopping_rounds offers a way to automatically find the ideal value. \n",
    "# Early stopping causes the model to stop iterating when the validation score stops improving, \n",
    "# even if we aren't at the hard stop for n_estimators. It's smart to set a high value for n_estimators \n",
    "# and then use early_stopping_rounds to find the optimal time to stop iterating.\n",
    "\n",
    "# Learning Rate: Instead of getting predictions by simply adding up the predictions from each component model, \n",
    "# we will multiply the predictions from each model by a small number before adding them in. \n",
    "# This means each tree we add to the ensemble helps us less. In practice, \n",
    "# this reduces the model's propensity to overfit. So, you can use a higher value of n_estimators without overfitting. \n",
    "\n",
    "# In general, a small learning rate (and large number of estimators) will yield more accurate XGBoost models, \n",
    "# though it will also take the model longer to train since it does more iterations through the cycle.\n",
    "\n",
    "#n_jobs: On larger datasets where runtime is a consideration, you can use parallelism to build your models faster.\n",
    "# It's common to set the parameter n_jobs equal to the number of cores on your machine. \n",
    "\n",
    "\n",
    "There's one piece outside that cycle. We need some base prediction to start the cycle. In practice, the initial predictions can be pretty naive. Even if it's predictions are wildly inaccurate, subsequent additions to the ensemble will address those errors.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "melbourne_file_path = \"/Users/nikschet/Documents/Jupyter Notebooks/melb_data.csv\"\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "melbourne_data = melbourne_data.dropna(axis=1)\n",
    "\n",
    "# Select certain column (Price) of melbourne_data\n",
    "y = melbourne_data.Price\n",
    "\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "my_model = XGBRegressor()\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "my_model = XGBRegressor(n_estimators=100, learning_rate=0.05)\n",
    "my_model.fit(train_X, train_y, early_stopping_rounds=5, \n",
    "             eval_set=[(val_X, val_y)], verbose=False)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "predictions = my_model.predict(val_X)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, val_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
